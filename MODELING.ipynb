{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0a0fc4d2-1bf7-4849-9477-c6b38a28151c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "490a4420-9a6d-4710-a80a-5c7ae4d21150",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "final_data = pd.read_csv('Final_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "769bbc1b-6583-4d3e-8435-ffdacc85515d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = final_data.drop('loan_status', axis = 1)\n",
    "y = final_data['loan_status']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1911008e-2344-4231-b85c-4ffd7826479a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ab174eb8-de6d-4a27-8c59-ca636c42df92",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "class XGBoostClassifier:\n",
    "    def __init__(self, n_estimators=3, max_depth=3, learning_rate=0.1):\n",
    "        self.n_estimators = n_estimators\n",
    "        self.max_depth = max_depth\n",
    "        self.learning_rate = learning_rate\n",
    "        self.estimators = []\n",
    "\n",
    "    def _softmax(self, x):\n",
    "        e_x = np.exp(x - np.max(x, axis=1, keepdims=True))\n",
    "        return e_x / np.sum(e_x, axis=1, keepdims=True)\n",
    "\n",
    "    def _log_loss_grad(self, y_true, y_pred):\n",
    "        return y_pred - self.y_encoded  # Menggunakan y_encoded sebagai target prediksi\n",
    "    \n",
    "    def _log_loss_hess(self, y_true, y_pred):\n",
    "        p = self._softmax(y_pred)\n",
    "        return p * (1 - p)\n",
    "    \n",
    "    def _split_data(self, X, y, feature_idx, threshold):\n",
    "        mask = X[:, feature_idx] < threshold\n",
    "        X_left = X[mask]\n",
    "        y_left = y[mask]\n",
    "        X_right = X[~mask]\n",
    "        y_right = y[~mask]\n",
    "        return X_left, y_left, X_right, y_right\n",
    "\n",
    "    def _gain(self, gradients, hessians):\n",
    "        gain = 0.5 * (np.sum(np.square(gradients)) /\n",
    "                     (np.sum(hessians) + 1e-8))\n",
    "        return gain\n",
    "\n",
    "    def _build_tree(self, X, y, depth):\n",
    "        if depth >= self.max_depth:\n",
    "            return None\n",
    "\n",
    "        n_samples, n_features = X.shape\n",
    "        n_classes = len(set(y))\n",
    "        best_gain = -1\n",
    "        best_feature_idx = None\n",
    "        best_threshold = None\n",
    "        best_X_left, best_y_left, best_X_right, best_y_right = None, None, None, None\n",
    "        X = X.to_numpy()\n",
    "\n",
    "        # Mendapatkan gradien dan hessian awal\n",
    "        gradients = self._log_loss_grad(y, self._softmax(np.zeros((n_samples, self.n_classes))))\n",
    "        hessians = self._log_loss_hess(y, self._softmax(np.zeros((n_samples, self.n_classes))))\n",
    "\n",
    "        for feature_idx in range(n_features):\n",
    "            thresholds = np.unique(X[:, feature_idx])\n",
    "            for threshold in thresholds:\n",
    "                X_left, y_left, X_right, y_right = self._split_data(X, y, feature_idx, threshold)\n",
    "                left_indices = np.where(X_left)[0]\n",
    "                right_indices = np.where(X_right)[0]\n",
    "                left_gradients = gradients[left_indices]\n",
    "                left_hessians = hessians[left_indices]\n",
    "                right_gradients = gradients[right_indices]\n",
    "                right_hessians = hessians[right_indices]\n",
    "                \n",
    "                def _split_gain(gradients_left, hessians_left, gradients_right, hessians_right, gradients, hessians): \n",
    "                    gain = (np.sum(gradients_left) ** 2 / (np.sum(hessians_left) + 1)) + (np.sum(gradients_right) ** 2 / (np.sum(hessians_right) + 1)) + (np.sum(gradients) ** 2 / (np.sum(hessians) + 1))\n",
    "                    return gain               \n",
    "                gain = _split_gain(left_gradients, left_hessians, right_gradients, right_hessians, gradients, hessians)\n",
    "                \n",
    "                if np.max(gain) > best_gain:\n",
    "                    best_gain = np.max(gain)\n",
    "                    best_feature_idx = feature_idx\n",
    "                    best_threshold = threshold\n",
    "                    best_X_left, best_y_left, best_X_right, best_y_right = X_left, y_left, X_right, y_right\n",
    "        return {\n",
    "            'feature_idx': self.best_feature_idx,\n",
    "            'threshold': self.best_threshold,\n",
    "            'left': self._build_tree(self.best_X_left, self.best_y_left, depth + 1),\n",
    "            'right': self._build_tree(self.best_X_right, self.best_y_right, depth + 1),\n",
    "            'depth': depth\n",
    "        }\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        self.n_classes = len(np.unique(y))\n",
    "        n_samples, n_features = X.shape   \n",
    "         # One-hot encoding label target\n",
    "        self.n_classes = len(set(y))\n",
    "        self.y_encoded = np.eye(self.n_classes)[y]\n",
    "        for _ in tqdm(range(self.n_estimators), desc=\"Training progress\"):\n",
    "            tree = self._build_tree(X, y, depth=0)\n",
    "            self.estimators.append(tree)1\n",
    "\n",
    "            # Dapatkan prediksi dari semua pohon sejauh ini\n",
    "            predictions = self.predict_proba(X)\n",
    "\n",
    "            # Hitung gradien dan hessian menggunakan log loss\n",
    "            gradients = self._log_loss_grad(y, predictions)\n",
    "            hessians = self._log_loss_hess(y, predictions)\n",
    "\n",
    "            # Update prediksi dengan gradien menggunakan learning rate\n",
    "            predictions -= self.learning_rate * gradients\n",
    "\n",
    "        return self\n",
    "\n",
    "    def predict_proba(self, X):\n",
    "        n_samples = X.shape[0]\n",
    "        n_classes = self.n_classes\n",
    "\n",
    "        # Inisialisasi matriks probabilitas prediksi dengan nol\n",
    "        proba = np.zeros((n_samples, n_classes))\n",
    "\n",
    "        # Prediksi dari setiap pohon\n",
    "        for tree in self.estimators:\n",
    "            node = tree\n",
    "            while node:\n",
    "                feature_idx = node['feature_idx']\n",
    "                threshold = node['threshold']\n",
    "\n",
    "                if X[:, feature_idx] < threshold:\n",
    "                    node = node['left']\n",
    "                else:\n",
    "                    node = node['right']\n",
    "\n",
    "            proba += node['prediction']\n",
    "\n",
    "        # Normalisasi probabilitas menggunakan softmax function\n",
    "        proba = self._softmax(proba)\n",
    "\n",
    "        return proba\n",
    "\n",
    "    def predict(self, X):\n",
    "        proba = self.predict_proba(X)\n",
    "        return np.argmax(proba, axis=1)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddcb2d1e-4259-43e7-ad8f-96b72e4ebfd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training progress:   0%|          | 0/3 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "label_encoder = LabelEncoder()\n",
    "y_train_encoded = label_encoder.fit_transform(y_train)\n",
    "\n",
    "# Menggunakan OneHotEncoder untuk melakukan one-hot encoding pada label numerik\n",
    "onehot_encoder = OneHotEncoder(sparse=False)\n",
    "y_train_encoded = y_train_encoded.reshape(-1, 1)\n",
    "y_train_onehot = onehot_encoder.fit_transform(y_train_encoded)\n",
    "\n",
    "# Mengubah one-hot encoding kembali menjadi label kelas asli\n",
    "y_train_restored = np.argmax(y_train_onehot, axis=1)\n",
    "\n",
    "# Membuat dan melatih model XGBoost\n",
    "xgb_classifier = XGBoostClassifier()\n",
    "xgb_classifier.fit(X_train, y_train_restored)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d23c5c47-c93a-413a-8151-34ce899c83cb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
